---
title: "Mar 1, Binomial Regression"
author: "Stephen R. Proulx"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rethinking)
library(bayesplot)
source("../helper.R")
```


# Today's objectives:  
* Learn about ways to use index and indicator variables to build models
* binomial regression
* Calculating contrasts from posterior parameter distributions
* Specifying models with contrasts built in. 


## The logistic function

The logit transformation maps numbers between 0 and 1 to numbers between -inf and inf. We will talk about mapping from the probabiliy scale to the logit scale, and vice-versa.
```{r}
logit_dat <- tibble( x= seq(from=0,to=1,by=0.001)) %>%
  mutate(y=logit(x))

ggplot(logit_dat, aes(x=x,y=y))+geom_line()
```


The inverse logit transformation maps numbers between between -inf and inf to numbers between 0 and 1. In our additive models we will be combining effects, how do these translate back to the probability scale?
```{r}
inv_logit_dat <- tibble( x= seq(from=-10,to=10,by=0.1)) %>%
  mutate(y=inv_logit(x) , y_add=inv_logit(x+0.5) , y_diff=y_add-y)

ggplot(inv_logit_dat, aes(x=x,y=y))+
  geom_line(color="black")+
  geom_line(aes(x=x,y=y_add) , color="red")

ggplot(inv_logit_dat, aes(x=x,y=y_diff))+
  geom_line(color="black")

```

The effect of our additive model on the probability scale is always dependent on both values that we are combining. This is why McElreath talks about interactions arising even when you don't build them in.   


## Binomial admissions

```{r}
## R code 11.28
library(rethinking)
data(UCBadmit)
d <- UCBadmit %>% 
  as_tibble() %>%
  mutate(gid= (applicant.gender=="male")*1+(applicant.gender=="female")*2,
         dept_id=as.integer( as.factor(dept)))
```


```{r}
## R code 11.29ish
m11.7 <- ulam(
    alist(
        admit ~ dbinom( applications , p ) ,
        logit(p) <- a[gid] ,
        a[gid] ~ dnorm( 0 , 1.5 )
    ) , data=select(d,admit,applications,gid) , chains=4, iter=3000 )
precis( m11.7 , depth=2 )
```


```{r}
## R code 11.30
post <- extract.samples(m11.7) %>% as_tibble()%>%
  mutate(diff_a=a[,1]-a[,2],
         diff_p=inv_logit(a[,1])-inv_logit(a[,2]))

mcmc_intervals(select(post,diff_a),prob_outer = 0.9) 
mcmc_intervals(select(post,diff_p),prob_outer = 0.9) 
```


### Posterior plots


```{r}
## R code 11.31
postcheck( m11.7 )
# draw lines connecting points from same dept
for ( i in 1:6 ) {
    x <- 1 + 2*(i-1)
    y1 <- d$admit[x]/d$applications[x]
    y2 <- d$admit[x+1]/d$applications[x+1]
    lines( c(x,x+1) , c(y1,y2) , col=rangi2 , lwd=2 )
    text( x+0.5 , (y1+y2)/2 + 0.05 , d$dept[x] , cex=0.8 , col=rangi2 )
}
```


A model that includes both an effect of gender, and an effect of department. Some departments are harder to get into than others, and some departments have more people admitted than others. 
```{r}
## R code 11.32

m11.8 <- ulam(
    alist(
        admit ~ dbinom( applications , p ) ,
        logit(p) <- a[gid] + delta[dept_id] ,
        a[gid] ~ dnorm( 0 , 1.5 ) ,
        delta[dept_id] ~ dnorm( 0 , 1.5 )
    ) , data=select(d,admit,applications,gid,dept_id) , cores=4, chains=4 , iter=4000, log_lik = TRUE)
precis( m11.8 , depth=2 )
```

```{r}
## R code 11.31
postcheck( m11.8 )
# draw lines connecting points from same dept
for ( i in 1:6 ) {
    x <- 1 + 2*(i-1)
    y1 <- d$admit[x]/d$applications[x]
    y2 <- d$admit[x+1]/d$applications[x+1]
    lines( c(x,x+1) , c(y1,y2) , col=rangi2 , lwd=2 )
    text( x+0.5 , (y1+y2)/2 + 0.05 , d$dept[x] , cex=0.8 , col=rangi2 )
}
```

We can again compute the contrasts:
```{r}
## R code 11.30
post <- extract.samples(m11.8) %>% as_tibble()%>%
  mutate(diff_a=a[,2]-a[,1])

mcmc_intervals(select(post,diff_a),prob_outer = 0.9) 
```

### Alternative formulations of the same model.

The alternate model where we force the `a` values to be a difference from an "intercept". In this version, `delta` acts as the intercept for each department, and a is the increase in admission rate (on the logit scale) for women.  
```{r}
m11.8A <- ulam(
    alist(
        admit ~ dbinom( applications , p ) ,
        logit(p) <- a*(gid-1)  + delta[dept_id] ,
        a ~ dnorm( 0 , 1.5 ) ,
        delta[dept_id] ~ dnorm( 0 , 1.5 )
    ) , data=select(d,admit,applications,gid,dept_id) , cores=4, chains=4 , iter=4000,log_lik = TRUE) 
```

Compare the intervals and standard deviations of the parameters in the two models, what do you notice?
```{r}
precis(m11.8, depth=2)
precis(m11.8A, depth=2)
```

Now compare the WAIC of the two models.
```{r}
compare(m11.8,m11.8A)
```

These models come up with the same actual predictions for admission probability, they just add together different quantities to get there. Compare this graph to the one we got with model 11.8:
```{r}
postcheck( m11.8A )
# draw lines connecting points from same dept
for ( i in 1:6 ) {
    x <- 1 + 2*(i-1)
    y1 <- d$admit[x]/d$applications[x]
    y2 <- d$admit[x+1]/d$applications[x+1]
    lines( c(x,x+1) , c(y1,y2) , col=rangi2 , lwd=2 )
    text( x+0.5 , (y1+y2)/2 + 0.05 , d$dept[x] , cex=0.8 , col=rangi2 )
}
```

What happens if you tighten the prior on a[gid] in model 11.8? Try it and see how it differs from the version we have already run. Try it and see:







### Contrasts for model 11.8

How should we evaluate the results from model 11.8? We need the contrast in a[1] and a[2]. Looking at the overlap of a[1] and a[2] is not enough;
```{r}
post.11.8 <- extract.samples(m11.8) %>% as_tibble()%>%
  mutate(diff_a=a[,2]-a[,1],
         a1=a[,1],
         a2=a[,2])
mcmc_intervals(select(post.11.8,a1,a2)) 

mcmc_intervals(select(post.11.8,diff_a)) +
  xlim(c(-0.1,0.3))

post.11.8A <- extract.samples(m11.8A) %>% as_tibble() %>%
   mutate(diff_a=a)
mcmc_intervals(select(post.11.8A,diff_a))  +
  xlim(c(-0.1,0.3))
```

Now make the graph of the contrasts on the probability scale. Because of the logit link you will have to do it for specific departments.


```{r}
post.11.8 <- extract.samples(m11.8) %>% as_tibble()%>%
  mutate(diff_a=a[,2]-a[,1],
         a1=a[,1],
         a2=a[,2],
         diff_p_1 = inv_logit(delta[,1]+a[,2])-inv_logit(delta[,1]+a[,1]),
          diff_p_2 = inv_logit(delta[,2]+a[,2])-inv_logit(delta[,2]+a[,1]), 
         diff_p_3 = inv_logit(delta[,3]+a[,2])-inv_logit(delta[,3]+a[,1]),
          diff_p_4 = inv_logit(delta[,4]+a[,2])-inv_logit(delta[,4]+a[,1]),
          diff_p_5 = inv_logit(delta[,5]+a[,2])-inv_logit(delta[,5]+a[,1]),
          diff_p_6 = inv_logit(delta[,6]+a[,2])-inv_logit(delta[,6]+a[,1]))


mcmc_intervals(select(post.11.8,diff_p_1,diff_p_2,diff_p_3,diff_p_4,diff_p_5,diff_p_6),prob_outer = 0.9) 
```




